# How Mercedes Natural Language Search Works

**Complete System Explanation with Flowcharts**

---

## Table of Contents
1. [System Overview](#system-overview)
2. [Where is Data Stored?](#where-is-data-stored)
3. [Complete Data Flow](#complete-data-flow)
4. [Component Breakdown](#component-breakdown)
5. [Detailed Process Flows](#detailed-process-flows)
6. [Advanced Features: Category Detection & Scalability](#advanced-features-category-detection--scalability)

---

## System Overview

This is a **hybrid search system** that combines semantic AI search with traditional keyword search to find medical/scientific products using natural language queries.

### The Big Picture

```mermaid
flowchart TB
    subgraph External["ğŸŒ External Data Sources"]
        API["Mercedes Scientific<br/>GraphQL API<br/>ğŸ“¦ 34,607 products"]
        OPENAI["OpenAI API<br/>ğŸ¤– GPT-4o-mini + Embeddings"]
    end

    subgraph System["Mercedes Search System"]
        FE["ğŸ‘¤ Frontend<br/>(React UI)"]
        FLASK["âš™ï¸ Flask API<br/>(Backend)"]
        TS["ğŸ” Typesense<br/>(Search Database)"]

        FE <--> FLASK
        FLASK <--> TS
        FLASK <--> OPENAI
    end

    API -.->|"Index Products"| TS

    style External fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style System fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#000
    style API fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style OPENAI fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style FE fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
    style FLASK fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
    style TS fill:#b2dfdb,stroke:#00796b,stroke-width:2px,color:#000
```

---

## Where is Data Stored?

### The `mercedes_products` Collection

**Answer**: The collection is stored in **Typesense**, which is a separate search engine database (similar to Elasticsearch).

```mermaid
graph TB
    subgraph TS["ğŸ” Typesense Database"]
        subgraph Config["âš™ï¸ Server Configuration"]
            HOST["ğŸŒ Host: TYPESENSE_HOST<br/>(from .env)"]
            PORT["ğŸ”Œ Port: 8108 or 443"]
            PROTO["ğŸ“¡ Protocol: http/https"]
            KEY["ğŸ”‘ API Key: TYPESENSE_API_KEY"]
        end

        subgraph Collection["ğŸ“¦ Collection: 'mercedes_products'"]
            P1["Product 1<br/>â”â”â”â”â”â”â”â”<br/>ğŸ“‹ id: 123<br/>ğŸ“ name: 'Sterile Nitrile Gloves'<br/>ğŸ’° price: 45.99<br/>ğŸ“„ description: '...'<br/>ğŸ§  embedding: [0.123, -0.456, ...]"]
            P2["Product 2<br/>â”â”â”â”â”â”â”â”<br/>ğŸ“‹ id: 124<br/>ğŸ“ name: 'Pipette Tips 1000Î¼L'<br/>ğŸ’° price: 89.50<br/>ğŸ§  embedding: [0.987, -0.654, ...]"]
            MORE["...<br/>34,607 products total"]

            P1 ~~~ P2 ~~~ MORE
        end

        subgraph Indexes["ğŸ—‚ï¸ Search Indexes"]
            FT["ğŸ“ Full-text Index<br/>(keyword search)"]
            VEC["ğŸ§  Vector Index<br/>(semantic search)"]
            FAC["ğŸ·ï¸ Facet Indexes<br/>(price, category filters)"]
        end
    end

    style TS fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#000
    style Config fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style Collection fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style Indexes fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style P1 fill:#f5f5f5,stroke:#616161,stroke-width:1px,color:#000
    style P2 fill:#f5f5f5,stroke:#616161,stroke-width:1px,color:#000
    style MORE fill:#f5f5f5,stroke:#616161,stroke-width:1px,color:#000
```

### Configuration (src/config.py)

```python
# Where Typesense is located
TYPESENSE_HOST = os.getenv("TYPESENSE_HOST", "localhost")
TYPESENSE_PORT = int(os.getenv("TYPESENSE_PORT", "8108"))
TYPESENSE_PROTOCOL = os.getenv("TYPESENSE_PROTOCOL", "http")
TYPESENSE_API_KEY = os.getenv("TYPESENSE_API_KEY")

# Collection name (where products are stored)
TYPESENSE_COLLECTION_NAME = "mercedes_products"
```

**Types of Typesense Deployments:**
- **Local**: Running on your computer (localhost:8108)
- **Cloud**: Running on Typesense Cloud (cloud.typesense.org)
- **Self-hosted**: Running on your own server

---

## Complete Data Flow

### Phase 1: Indexing (One-Time Setup)

This happens when you run `python src/indexer.py`:

```mermaid
sequenceDiagram
    participant User
    participant Indexer as indexer.py
    participant API as Mercedes GraphQL API
    participant Typesense
    participant OpenAI

    User->>Indexer: python src/indexer.py

    Note over Indexer: STEP 1: Create Collection
    Indexer->>Typesense: create_collection()
    Note over Typesense: Creates schema:<br/>â€¢ product_id, name, sku, price<br/>â€¢ embedding field (float[])
    Typesense-->>Indexer: Collection created âœ“

    Note over Indexer: STEP 2: Fetch Products
    Note over Indexer: Multi-Search Strategy<br/>(bypass 500-product limit)

    loop For each search term (110+ terms)
        Indexer->>API: GraphQL query (search: "a")
        API-->>Indexer: Up to 500 products
        Note over Indexer: De-duplicate by SKU
    end

    Note over Indexer: Result: 34,607 unique products

    Note over Indexer: STEP 3: Index to Typesense

    loop For each batch (100 products)
        Indexer->>Typesense: Send product data
        Typesense->>OpenAI: Generate embeddings
        Note over OpenAI: text-embedding-3-small<br/>"Sterile Nitrile Gloves..."
        OpenAI-->>Typesense: [0.123, -0.456, 0.789, ...]
        Typesense-->>Indexer: Batch indexed âœ“
    end

    Note over Indexer,Typesense: All products indexed<br/>with AI embeddings âœ“
    Indexer-->>User: Indexing complete!<br/>Ready for search
```

**Time**: ~10-20 minutes for 5,000-10,000 products

---

### Phase 2: Searching (Runtime)

This happens when a user searches:

```mermaid
sequenceDiagram
    participant User
    participant Frontend as React UI
    participant Flask as Flask API
    participant Search as search.py
    participant GPT4 as OpenAI GPT-4o-mini
    participant Typesense
    participant OpenAI as OpenAI Embeddings

    User->>Frontend: Types "gloves under $50"
    Frontend->>Flask: POST /api/search<br/>{query: "gloves under $50"}

    Note over Flask: Validate with Pydantic

    Flask->>Search: search_engine.search()

    Note over Search: STEP 1: Query Translation

    Search->>GPT4: Translate query
    Note over GPT4: System Prompt:<br/>"Convert natural language<br/>to Typesense parameters..."
    GPT4-->>Search: {<br/>  q: "gloves",<br/>  filter_by: "price:[0..50]",<br/>  sort_by: "price:asc"<br/>}
    Note over Search: Time: ~50-100ms

    Note over Search: STEP 2: Hybrid Search

    Search->>Typesense: Execute hybrid search
    Note over Typesense: Search Parameters:<br/>â€¢ q: "gloves"<br/>â€¢ filter_by: "price:[0..50]"<br/>â€¢ vector_query: embedding

    par Semantic Search
        Typesense->>OpenAI: Generate query embedding
        OpenAI-->>Typesense: [0.1, -0.3, ...]
        Note over Typesense: Find similar vectors:<br/>â€¢ Hand covering<br/>â€¢ Protective gloves<br/>â€¢ Safety gear
    and Keyword Search
        Note over Typesense: Full-text search:<br/>â€¢ name field<br/>â€¢ description field<br/>â€¢ SKU field
    end

    Note over Typesense: Merge & Rank Results<br/>Apply filters & sorting
    Typesense-->>Search: Ranked results
    Note over Search: Time: ~10-50ms

    Note over Search: STEP 3: Transform Results<br/>Typesense docs â†’ Product models

    Search-->>Flask: SearchResponse
    Flask-->>Frontend: JSON Response<br/>{results: [...], total: 47}
    Frontend-->>User: Display products âœ“

    Note over User,Frontend: Total Time: ~100-200ms
```

**Total Time**: ~100-200ms

---

## Component Breakdown

### 1. Configuration (src/config.py)

**Purpose**: Central configuration management

**What it does:**
- Loads environment variables from `.env` file
- Stores API keys (OpenAI, Typesense)
- Stores connection settings (URLs, ports)
- Validates required settings on startup

**Key Settings:**
```python
OPENAI_API_KEY          # For GPT-4 and embeddings
OPENAI_MODEL            # gpt-4 (query translation)
OPENAI_EMBEDDING_MODEL  # text-embedding-3-small (vectors)

TYPESENSE_HOST          # Where Typesense is running
TYPESENSE_PORT          # Connection port
TYPESENSE_API_KEY       # Authentication
TYPESENSE_COLLECTION_NAME = "mercedes_products"  â† Collection name!

MERCEDES_GRAPHQL_URL    # Where to fetch products from
```

---

### 2. Data Models (src/models.py)

**Purpose**: Type-safe data validation with Pydantic

**Models:**
```python
SearchQuery         # User input validation
  â”œâ”€ query: str
  â””â”€ max_results: int

SearchResponse      # API response format
  â”œâ”€ results: List[Product]
  â”œâ”€ total: int
  â”œâ”€ query_time_ms: float
  â””â”€ typesense_query: dict

Product            # Product data structure
  â”œâ”€ product_id, name, sku
  â”œâ”€ price, currency
  â”œâ”€ description, categories
  â””â”€ stock_status, image_url

TypesenseQuery     # Internal search parameters
  â”œâ”€ q: str
  â”œâ”€ filter_by: Optional[str]
  â”œâ”€ sort_by: Optional[str]
  â””â”€ per_page: int
```

---

### 3. Indexer (src/indexer.py)

**Purpose**: Fetch products from Mercedes API and index to Typesense

**Flow:**
```
MercedesProductIndexer.run()
    â†“
1. create_collection()
   â””â”€ Creates "mercedes_products" collection
   â””â”€ Defines schema with embedding field
    â†“
2. fetch_products()
   â”œâ”€ _get_search_terms() â†’ 110+ search terms
   â””â”€ _fetch_products_for_search() for each term
       â”œâ”€ Query GraphQL API
       â”œâ”€ Get up to 500 products per term
       â””â”€ De-duplicate by SKU
   Result: 5,000-10,000+ unique products
    â†“
3. index_products()
   â””â”€ Batch upload to Typesense (100 per batch)
   â””â”€ Typesense auto-generates embeddings via OpenAI
```

**Why Multi-Search?**
```
Mercedes GraphQL API Limitation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Max products per query: 500            â”‚
â”‚ No matter what search term you use!    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Solution: Multiple searches with different terms
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search "a"          â†’  500 products (100 unique)    â”‚
â”‚ Search "b"          â†’  500 products (98 unique)     â”‚
â”‚ Search "gloves"     â†’  500 products (450 unique)    â”‚
â”‚ Search "pipette"    â†’  500 products (480 unique)    â”‚
â”‚ ...                                                  â”‚
â”‚ (110+ search terms)                                  â”‚
â”‚                                                      â”‚
â”‚ Result: 5,000-10,000+ unique products!              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4. Search Engine (src/search.py)

**Purpose**: Natural language search with hybrid AI + keyword

**Main Class: NaturalLanguageSearch**

**Flow:**
```
search(query, max_results)
    â†“
1. _convert_to_typesense_query()
   â”œâ”€ Sends query to GPT-4
   â”œâ”€ GPT-4 extracts: keywords, filters, sort
   â””â”€ Returns TypesenseQuery object
    â†“
2. _execute_search()
   â”œâ”€ Builds hybrid search parameters
   â”œâ”€ vector_query = semantic search (AI)
   â”œâ”€ query_by = keyword search (full-text)
   â””â”€ Executes on Typesense
    â†“
3. _transform_results()
   â”œâ”€ Converts Typesense documents
   â””â”€ Returns List[Product]
    â†“
Returns SearchResponse
```

**Hybrid Search Magic:**
```python
search_params = {
    "q": "gloves",                           # â† Keyword search
    "query_by": "name,description,sku,...",  # â† Fields to search
    "vector_query": "embedding:(gloves, k:40)"  # â† Semantic search!
}
```

This searches BOTH ways simultaneously:
- **Keyword**: Exact matches for "gloves"
- **Semantic**: Similar concepts (hand protection, protective gear, etc.)

---

### 5. Flask API (src/app.py)

**Purpose**: REST API server

**Endpoints:**
```
GET  /              â†’ API info
GET  /health        â†’ Health check
POST /api/search    â†’ Search (JSON body)
GET  /api/search    â†’ Search (query params)
```

**Request Flow:**
```
POST /api/search
Body: {"query": "gloves under $50", "max_results": 20}
    â†“
1. Validate with Pydantic (SearchQuery)
2. Call search_engine.search()
3. Convert response to JSON (Pydantic â†’ dict)
4. Return JSON to client
```

---

## Detailed Process Flows

### Embedding Generation (How AI Vectors Work)

**During Indexing:**

```
Product: "Sterile Nitrile Exam Gloves, Powder-Free, Large"
    â†“
Typesense sends to OpenAI:
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI text-embedding-3-small API                   â”‚
â”‚                                                      â”‚
â”‚ Input: "Sterile Nitrile Exam Gloves, Powder-Free,   â”‚
â”‚         Large. Medical grade disposable gloves..."   â”‚
â”‚                                                      â”‚
â”‚         â†“ (AI Processing)                           â”‚
â”‚                                                      â”‚
â”‚ Output: 1536-dimensional vector                     â”‚
â”‚ [0.123, -0.456, 0.789, -0.234, 0.567, ...]          â”‚
â”‚                                                      â”‚
â”‚ This vector represents the MEANING of the text      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Stored in Typesense as "embedding" field
```

**During Search:**

```
User Query: "hand protection for medical use"
    â†“
Typesense converts to embedding:
    â†“
Query Vector: [0.111, -0.444, 0.777, ...]
    â†“
Finds similar vectors using cosine similarity:
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Compare query vector with all product vectors    â”‚
â”‚                                                   â”‚
â”‚ Product 1: [0.123, -0.456, 0.789, ...]           â”‚
â”‚   Similarity: 0.92 (very similar!)               â”‚
â”‚   â†’ "Sterile Nitrile Exam Gloves"               â”‚
â”‚                                                   â”‚
â”‚ Product 2: [0.100, -0.300, 0.600, ...]           â”‚
â”‚   Similarity: 0.85 (similar)                     â”‚
â”‚   â†’ "Latex Medical Gloves"                       â”‚
â”‚                                                   â”‚
â”‚ Product 3: [0.900, 0.800, -0.700, ...]           â”‚
â”‚   Similarity: 0.12 (not similar)                 â”‚
â”‚   â†’ "Microscope Slide Holder"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Returns top-K most similar products
```

**Why This is Powerful:**

```
Traditional Keyword Search:
  Query: "hand protection"
  Results: Only products with "hand" OR "protection"
  Misses: "gloves", "safety gear", "PPE"

Semantic Search (AI Embeddings):
  Query: "hand protection"
  Results: Products with similar MEANING
  Finds: "gloves", "safety gear", "PPE", "protective equipment"
         even if they don't contain exact words!
```

---

### GPT-4 Query Translation

**Input â†’ Output Examples:**

```
Example 1:
Input:  "gloves under $50"
GPT-4 analyzes and extracts:
  â€¢ Keywords: "gloves"
  â€¢ Price filter: under $50
  â€¢ Sort preference: cheapest first

Output: {
  "q": "gloves",
  "filter_by": "price:[0..50]",
  "sort_by": "price:asc"
}

Example 2:
Input:  "sterile surgical instruments in stock"
GPT-4 extracts:
  â€¢ Keywords: "sterile surgical instruments"
  â€¢ Stock filter: only in stock
  â€¢ No price constraint
  â€¢ No sort preference

Output: {
  "q": "sterile surgical instruments",
  "filter_by": "stock_status:=IN_STOCK",
  "sort_by": null
}

Example 3:
Input:  "chemistry reagents between $50 and $200"
GPT-4 extracts:
  â€¢ Keywords: "chemistry reagents"
  â€¢ Price range: $50-$200
  â€¢ Sort: price ascending

Output: {
  "q": "chemistry reagents",
  "filter_by": "price:[50..200]",
  "sort_by": "price:asc"
}
```

**System Prompt Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System Prompt to GPT-4:                        â”‚
â”‚                                                 â”‚
â”‚ 1. Here's the database schema                  â”‚
â”‚    - Available fields                          â”‚
â”‚    - Major categories                          â”‚
â”‚                                                 â”‚
â”‚ 2. Here's the filter syntax                    â”‚
â”‚    - price:[min..max]                          â”‚
â”‚    - field:=value                              â”‚
â”‚    - Boolean operators                         â”‚
â”‚                                                 â”‚
â”‚ 3. Here are examples                           â”‚
â”‚    - Query â†’ Output mapping                    â”‚
â”‚    - Various query types                       â”‚
â”‚                                                 â”‚
â”‚ 4. Return JSON format                          â”‚
â”‚    - q, filter_by, sort_by                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Error Handling & Fallbacks

**Fallback Strategy:**

```
TRY: Hybrid Search (Semantic + Keyword)
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Search with:                        â”‚
    â”‚ â€¢ Keyword search                    â”‚
    â”‚ â€¢ Vector search (embeddings)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    SUCCESS? â†’ Return results
    â†“
    FAIL? (e.g., Typesense version too old)
    â†“
FALLBACK: Keyword-Only Search
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Search with:                        â”‚
    â”‚ â€¢ Keyword search only               â”‚
    â”‚ â€¢ Remove vector_query parameter     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    SUCCESS? â†’ Return results
    â†“
    FAIL? â†’ Return empty results
```

**Graceful Degradation:**
1. **Best Case**: Hybrid search with AI
2. **Fallback**: Keyword-only search (still works!)
3. **Worst Case**: Empty results with error message

---

## Architecture Diagram (Full System)

```mermaid
flowchart TB
    subgraph External["ğŸŒ External Services"]
        direction TB
        OPENAI_EXT["ğŸ¤– OpenAI API<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ GPT-4o-mini (query translation)<br/>â€¢ text-embedding-3-small<br/>â€¢ Rate limits"]
        MERCEDES["ğŸ“¦ Mercedes Scientific<br/>GraphQL API<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ 34,607 products<br/>â€¢ No API limits (Neon DB)"]
    end

    subgraph App["Your Application"]
        direction TB

        subgraph Backend["Backend Services"]
            direction TB
            INDEXER["ğŸ”„ Python Indexer<br/>(src/indexer_neon.py)<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>1. Fetch from Neon DB<br/>2. De-duplicate<br/>3. Batch upload"]

            TS["ğŸ” Typesense Database<br/>(Search Engine)<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>Collection: mercedes_products<br/>â€¢ 34,607 products<br/>â€¢ Full-text index<br/>â€¢ Vector index<br/>â€¢ Faceted fields"]

            SEARCH["ğŸ” Search Engine<br/>(src/search.py)<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Query translation<br/>â€¢ Hybrid search exec<br/>â€¢ Result transformation"]

            FLASK["âš™ï¸ Flask API Server<br/>(src/app.py)<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ POST /api/search<br/>â€¢ GET /api/search<br/>â€¢ GET /health<br/>â€¢ CORS enabled"]
        end

        FE["ğŸ‘¤ React UI<br/>(frontend/)<br/>â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Search input box<br/>â€¢ Results display<br/>â€¢ Product cards<br/>â€¢ Filters & sorting"]
    end

    MERCEDES -.->|"Index Products"| INDEXER
    INDEXER -->|"Batch upload"| TS
    TS -->|"Query data"| SEARCH
    SEARCH -->|"Uses for translation"| OPENAI_EXT
    SEARCH -->|"Search API"| FLASK
    FLASK <-->|"HTTP/JSON"| FE

    style External fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000
    style App fill:#e8f5e9,stroke:#388e3c,stroke-width:3px,color:#000
    style Backend fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style OPENAI_EXT fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style MERCEDES fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
    style INDEXER fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
    style TS fill:#b2dfdb,stroke:#00796b,stroke-width:2px,color:#000
    style SEARCH fill:#f8bbd0,stroke:#ad1457,stroke-width:2px,color:#000
    style FLASK fill:#c5cae9,stroke:#3949ab,stroke-width:2px,color:#000
    style FE fill:#ffccbc,stroke:#d84315,stroke-width:2px,color:#000
```

---

## Summary: Key Concepts

### 1. **Typesense = Your Database**
- Stores all products in collection "mercedes_products"
- Runs as separate service (localhost or cloud)
- Configured via environment variables

### 2. **Hybrid Search = AI + Traditional**
- **Semantic**: Understands meaning (via embeddings)
- **Keyword**: Exact text matching
- **Combined**: Best of both worlds

### 3. **Multi-Search Strategy**
- Mercedes API limits: 500 products/query
- Solution: 110+ different searches
- Result: 5,000-10,000+ unique products

### 4. **Two-Phase System**
- **Phase 1 (Indexing)**: Fetch & store products once
- **Phase 2 (Search)**: Fast queries at runtime

### 5. **AI Components**
- **GPT-4**: Translates natural language â†’ structured query
- **Embeddings**: Converts text â†’ vectors for similarity search
- **Both**: Handled by OpenAI API

---

## Quick Reference

### File Purposes
```
src/
â”œâ”€â”€ config.py      â†’ Configuration & environment variables
â”œâ”€â”€ models.py      â†’ Data models (Pydantic)
â”œâ”€â”€ indexer.py     â†’ Fetch products & index to Typesense
â”œâ”€â”€ search.py      â†’ Natural language search engine
â””â”€â”€ app.py         â†’ Flask REST API server

.env               â†’ Secret keys & configuration
requirements.txt   â†’ Python dependencies
```

### Data Flow Summary
```
Indexing:
Mercedes API â†’ Indexer â†’ Typesense (with OpenAI embeddings)

Searching:
User â†’ Frontend â†’ Flask API â†’ Search Engine â†’ GPT-4 & Typesense â†’ Results
```

### Collection Location
```
Physical Storage: Typesense database server
Collection Name: "mercedes_products"
Access: Via Typesense client (config from .env)
```

---

**Questions?**

1. **Where is the collection?** â†’ In Typesense database (separate service)
2. **How does AI work?** â†’ Embeddings convert text to vectors for similarity
3. **Why hybrid search?** â†’ Combines semantic understanding + exact matching
4. **How to bypass 500-product limit?** â†’ Multiple searches with different terms
5. **What stores the data?** â†’ Typesense (not your local filesystem!)

---

## Advanced Features: Category Detection & Scalability

### Category Detection (No Hardcoding Needed!)

**How it works:**

```mermaid
flowchart TB
    A["User Query:<br/>'nitrile gloves under $30'"] --> B["Single GPT-4o-mini Call<br/>(~50-100ms)"]

    B --> C["Extract Product Type:<br/>'nitrile glove'"]
    B --> D["Extract ALL Filters:<br/>price:<30"]

    C --> E["Semantic Matching<br/>(Vector Search)"]
    E --> F["Category: 'Products/Gloves'<br/>Confidence: 0.95"]

    D --> G["Final Query"]
    F --> G

    G --> H["Search with filters + category"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#000
    style C fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style D fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style E fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style F fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
```

**Key Points:**
1. **NO hardcoded categories** - System uses semantic matching via embeddings
2. **Filters extracted in parallel** - Not dependent on category detection
3. **Single LLM call** - Everything extracted simultaneously (product type + all filters)
4. **Scales infinitely** - Prompt size stays constant (~2.3K chars) regardless of catalog size

### Confidence Scoring

**How confidence is calculated:**

```mermaid
flowchart TB
    A["Query: 'nitrile gloves'<br/>Returns 20 results"] --> B["Count Category Matches"]

    B --> C["19 products in<br/>'Products/Gloves'"]
    B --> D["1 product in<br/>'Products/Lab Coats'"]

    C --> E["Calculate Confidence:<br/>19 Ã· 20 = 0.95"]
    D --> E

    E --> F{"Confidence â‰¥ Threshold?<br/>(0.95 â‰¥ 0.80)"}

    F -->|"YES"| G["âœ… Apply Category Filter<br/>category_applied: true<br/>Very High confidence (0.8-1.0)"]
    F -->|"NO"| H["âš ï¸ Skip Category Filter<br/>category_applied: false<br/>Show all results"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style E fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style F fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#000
    style G fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style H fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
```

**Confidence Score Scale:**
- **0.8-1.0**: Very High - Apply category filter âœ…
- **0.6-0.8**: High - Consider applying
- **0.4-0.6**: Moderate - Don't apply (too ambiguous)
- **0.2-0.4**: Low - Don't apply
- **0.0-0.2**: Very Low - Don't apply

**Configurable threshold:**
```python
# Default threshold: 0.80
response = search_engine.search(
    query="nitrile gloves",
    confidence_threshold=0.80  # Only apply category if confidence >= 80%
)
```

**Response includes:**
```json
{
  "detected_category": "Products/Gloves",
  "category_confidence": 0.95,
  "category_applied": true,
  "confidence_threshold": 0.80
}
```

### Scalability Metrics

**Performance stays constant regardless of catalog size:**

```mermaid
flowchart LR
    subgraph Cat100["100 Categories"]
        P100["Prompt: 2.3K chars"]
        T100["Time: 80-150ms"]
        C100["Cost: $0.01"]
    end

    subgraph Cat1K["1,000 Categories"]
        P1K["Prompt: 2.3K chars"]
        T1K["Time: 80-150ms"]
        C1K["Cost: $0.01"]
    end

    subgraph Cat10K["10,000 Categories"]
        P10K["Prompt: 2.3K chars"]
        T10K["Time: 80-150ms"]
        C10K["Cost: $0.01"]
    end

    subgraph CatUnlimited["Unlimited Categories"]
        PU["Prompt: 2.3K chars"]
        TU["Time: 80-150ms"]
        CU["Cost: $0.01"]
    end

    Cat100 --> Cat1K --> Cat10K --> CatUnlimited

    style Cat100 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000
    style Cat1K fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000
    style Cat10K fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000
    style CatUnlimited fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px,color:#000
```

**Why it scales infinitely:**
- âœ… **Schema-driven filter extraction** - Universal rules for all products
- âœ… **Semantic category matching** - No category list in prompt
- âœ… **Result-based confidence** - No additional LLM call needed
- âœ… **Constant prompt size** - Always ~2.3K chars (574 tokens)

### Filter Extraction (Independent of Category)

**Common Misconception:**
> "You need to identify the category BEFORE extracting filters"

**Reality:**

```mermaid
flowchart TB
    A["User Query:<br/>'Mercedes blue gloves<br/>size medium under $30'"] --> B["Single GPT-4o-mini Call<br/>(~50-100ms)"]

    B --> C["PARALLEL Extraction<br/>(Everything at once!)"]

    C --> D1["Product Type:<br/>'glove'"]
    C --> D2["Brand:<br/>'Mercedes Scientific'"]
    C --> D3["Color:<br/>'Blue'"]
    C --> D4["Size:<br/>'Medium'"]
    C --> D5["Price:<br/>'<30'"]

    D1 --> E["Combine into<br/>Structured Query"]
    D2 --> E
    D3 --> E
    D4 --> E
    D5 --> E

    E --> F["{<br/>  q: 'glove',<br/>  filter_by: 'brand + color + size + price'<br/>}"]

    F --> G["THEN (separate process):<br/>Semantic Matching"]
    G --> H["Category: 'Products/Gloves'<br/>(found via vector search)"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#000
    style C fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style D1 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style D2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style D3 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style D4 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style D5 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style F fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
    style H fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
```

**Key Insight:** Filters are extracted FROM THE QUERY TEXT, not from the category!

**Benefits:**
- âœ… Single LLM call (not two)
- âœ… 2-3x faster (80-150ms vs 210-420ms)
- âœ… 3x cheaper ($0.01 vs $0.03 per search)
- âœ… Same filters work for ALL categories

### Supported Query Types

**All of these work WITHOUT hardcoding specific categories:**

```mermaid
flowchart TB
    A["Natural Language Query"] --> B1["Price & Inventory"]
    A --> B2["Brand & Attributes"]
    A --> B3["Temporal & Sorting"]
    A --> B4["Complex Multi-Filter"]

    B1 --> C1["'gloves under $30'<br/>'products on sale under $50'<br/>'items in stock'<br/>'reagents between $100 and $500'"]

    B2 --> C2["'Mercedes Scientific pipettes'<br/>'nitrile gloves size medium'<br/>'white lab coats size large'<br/>'clear liquid chemicals 1 gallon'"]

    B3 --> C3["'latest microscopes'<br/>'newest products'<br/>'cheapest centrifuge'"]

    B4 --> C4["'Mercedes blue nitrile gloves<br/>size medium under $25 in stock'<br/>(5+ filters in one query!)"]

    C1 --> D["Single GPT-4o-mini Call<br/>Extracts ALL filters"]
    C2 --> D
    C3 --> D
    C4 --> D

    D --> E["Semantic Matching<br/>Finds Category"]

    E --> F["âœ… Works for ANY category!<br/>No hardcoded mappings needed"]

    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style B1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style B2 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style B3 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style B4 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style D fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style E fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
    style F fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px,color:#000
```

---

**Last Updated**: 2025-10-15
**Document Version**: 2.0